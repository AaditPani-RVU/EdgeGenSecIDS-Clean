{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9351aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 220.7224\n",
      "Epoch 2/15, Loss: 67.3000\n",
      "Epoch 3/15, Loss: 53.0356\n",
      "Epoch 4/15, Loss: 47.1625\n",
      "Epoch 5/15, Loss: 44.9223\n",
      "Epoch 6/15, Loss: 41.3076\n",
      "Epoch 7/15, Loss: 39.1202\n",
      "Epoch 8/15, Loss: 37.7883\n",
      "Epoch 9/15, Loss: 37.3028\n",
      "Epoch 10/15, Loss: 34.9120\n",
      "Epoch 11/15, Loss: 34.7965\n",
      "Epoch 12/15, Loss: 34.1921\n",
      "Epoch 13/15, Loss: 32.7747\n",
      "Epoch 14/15, Loss: 30.8445\n",
      "Epoch 15/15, Loss: 31.6988\n",
      "\n",
      "ðŸ“Š Multiclass IDS Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1000\n",
      "           1       0.99      1.00      0.99      1000\n",
      "           2       0.99      1.00      0.99      1000\n",
      "           3       0.97      1.00      0.98      1000\n",
      "           4       0.99      0.99      0.99      1000\n",
      "           5       0.99      0.99      0.99      1000\n",
      "           6       0.99      0.99      0.99      1000\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.75      0.86      0.80         7\n",
      "           9       0.98      1.00      0.99      1000\n",
      "          10       0.96      1.00      0.98      1000\n",
      "          11       0.68      0.91      0.78       302\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       1.00      0.01      0.02       131\n",
      "          14       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           0.97     10446\n",
      "   macro avg       0.88      0.84      0.83     10446\n",
      "weighted avg       0.97      0.97      0.97     10446\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 903   13    6   26    2    2    8    0    2   21   11    6    0    0\n",
      "     0]\n",
      " [   1  999    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0  998    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    1    1  997    0    0    1    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0    2    0  992    4    0    0    0    0    0    1    0    0\n",
      "     0]\n",
      " [   2    0    0    0    9  988    0    0    0    0    1    0    0    0\n",
      "     0]\n",
      " [   0    0    0    2    0    4  994    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    2    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0    0    0    0    0    0    0    6    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0    0    0    0    1    0    0    0  998    0    0    0    0\n",
      "     0]\n",
      " [   0    0    1    0    0    0    2    0    0    0  997    0    0    0\n",
      "     0]\n",
      " [   1    0    0    0    0    0    0    0    0    0   27  274    0    0\n",
      "     0]\n",
      " [   0    0    1    0    0    0    0    0    0    0    3    0    0    0\n",
      "     0]\n",
      " [   2    0    0    4    0    0    0    0    0    0    1  123    0    1\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  1000]]\n",
      "âœ… Saved: ids_cnn_multiclass.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aadip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\aadip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\aadip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# === ONLY NEW IMPORTS ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# === Load and Preprocess CSV ===\n",
    "df = pd.read_csv(\"CICIDS2017_Multiclass_Balanced_5k.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# === Label Encoding ===\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "df['Label'] = label_encoder.transform(df['Label'].astype(str))\n",
    "\n",
    "# === Drop non-numeric columns ===\n",
    "non_numerics = df.select_dtypes(include=['object']).columns\n",
    "df = df.drop(non_numerics.difference(['Label']), axis=1)\n",
    "\n",
    "# === Synthetic Data Generation Placeholder ===\n",
    "def generate_synthetic_data(target_size, feature_columns):\n",
    "    np.random.seed(42)\n",
    "    synthetic_data = np.random.normal(loc=0.0, scale=1.0, size=(target_size, len(feature_columns)))\n",
    "    return pd.DataFrame(synthetic_data, columns=feature_columns)\n",
    "\n",
    "# === Load synthetic data generated by GAN ===\n",
    "df_synthetic = generate_synthetic_data(target_size=5000, feature_columns=df.columns[:-1])\n",
    "df_synthetic['Label'] = df['Label'].max() + 1  # Label for synthetic attack\n",
    "\n",
    "# === Combine real + synthetic data ===\n",
    "feature_cols = df.drop(\"Label\", axis=1).columns.tolist()\n",
    "df_combined = pd.concat([df, df_synthetic], ignore_index=True)\n",
    "\n",
    "# === Feature/Label separation and standardization ===\n",
    "X = df_combined[feature_cols].values\n",
    "y = df_combined[\"Label\"].values\n",
    "input_len = len(feature_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "with open(\"features_list.pkl\", \"wb\") as f:\n",
    "    joblib.dump(feature_cols, f)\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === Torch Dataloaders ===\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=128)\n",
    "\n",
    "# === Multiclass CNN Architecture ===\n",
    "class CNNMulticlassIDS(nn.Module):\n",
    "    def __init__(self, input_len, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((input_len // 4) * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# === Training ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(np.unique(y))\n",
    "model = CNNMulticlassIDS(input_len=input_len, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"\\n\\U0001F4CA Multiclass IDS Evaluation:\")\n",
    "print(classification_report(y_test, all_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, all_preds))\n",
    "\n",
    "# === Save TorchScript model ===\n",
    "example_input = torch.rand(1, 1, input_len).to(device)\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model.save(\"ids_cnn_multiclass.pt\")\n",
    "print(\"âœ… Saved: ids_cnn_multiclass.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
